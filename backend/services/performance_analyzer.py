from typing import Dict, Any, List
import json

def analyze_user_performance(user_id: str, skill_category: str, level: str) -> Dict[str, Any]:
    """
    × ×™×ª×•×— ×‘×™×¦×•×¢×™ ××©×ª××© (×›×¨×’×¢ ××—×–×™×¨ × ×ª×•× ×™× ×“××”)
    ×‘×¢×ª×™×“ ×™×ª×—×‘×¨ ×œ××¡×“ × ×ª×•× ×™× ×××™×ª×™
    """
    
    print(f"ğŸ“Š ×× ×ª×— ×‘×™×¦×•×¢×™× ×¢×‘×•×¨ ××©×ª××© {user_id}")
    
    # × ×ª×•× ×™× ×“××” ×œ×‘×“×™×§×”
    # ×‘×¢×ª×™×“ ×–×” ×™×‘×•× ×××¡×“ × ×ª×•× ×™× ×××™×ª×™
    mock_analytics = {
        "comprehension_ecrite": {
            "accuracy_rate": 0.75,
            "average_time_per_exercise": 180,  # 3 ×“×§×•×ª
            "improvement_rate": 0.15,
            "consistency_score": 0.8,
            "common_errors": [
                {"type": "vocabulary", "count": 5},
                {"type": "grammar", "count": 3}
            ],
            "strong_areas": ["basic_vocabulary", "simple_sentences"],
            "weak_areas": ["complex_grammar", "long_texts"]
        },
        "production_ecrite": {
            "accuracy_rate": 0.65,
            "average_time_per_exercise": 300,  # 5 ×“×§×•×ª
            "improvement_rate": 0.1,
            "consistency_score": 0.6,
            "common_errors": [
                {"type": "grammar", "count": 8},
                {"type": "spelling", "count": 4}
            ],
            "strong_areas": ["basic_vocabulary"],
            "weak_areas": ["verb_conjugation", "sentence_structure"]
        },
        "comprehension_orale": {
            "accuracy_rate": 0.7,
            "average_time_per_exercise": 240,
            "improvement_rate": 0.2,
            "consistency_score": 0.7,
            "common_errors": [
                {"type": "pronunciation", "count": 6},
                {"type": "speed", "count": 4}
            ],
            "strong_areas": ["basic_words"],
            "weak_areas": ["fast_speech", "accents"]
        },
        "production_orale": {
            "accuracy_rate": 0.6,
            "average_time_per_exercise": 120,
            "improvement_rate": 0.05,
            "consistency_score": 0.5,
            "common_errors": [
                {"type": "pronunciation", "count": 10},
                {"type": "fluency", "count": 7}
            ],
            "strong_areas": ["basic_phrases"],
            "weak_areas": ["pronunciation", "sentence_formation"]
        }
    }
    
    # ×”×—×–×¨×ª analytics ×œ×¤×™ ×”××™×•×× ×•×ª ×”××‘×•×§×©×ª
    analytics = mock_analytics.get(skill_category, mock_analytics["comprehension_ecrite"])
    
    # ×”×ª×××” ×œ×¨××”
    if level == "A1":
        # ×¨××” A1 - ×‘×™×¦×•×¢×™× × ××•×›×™× ×™×•×ª×¨ ×–×” × ×•×¨××œ×™
        analytics["accuracy_rate"] = max(0.5, analytics["accuracy_rate"] - 0.1)
    elif level == "A2":
        # ×¨××” A2 - ×‘×™×¦×•×¢×™× ×§×¦×ª ×™×•×ª×¨ ×’×‘×•×”×™×
        analytics["accuracy_rate"] = min(0.9, analytics["accuracy_rate"] + 0.05)
    
    print(f"âœ… × ×™×ª×•×— ×”×•×©×œ×: ×“×™×•×§ {analytics['accuracy_rate']:.0%}")
    
    return analytics


def calculate_adaptive_difficulty(base_difficulty: int, analytics: Dict[str, Any]) -> int:
    """
    ×—×™×©×•×‘ ×¨××ª ×§×•×©×™ ××•×ª×××ª ×œ×¤×™ ×‘×™×¦×•×¢×™ ×”××©×ª××©
    """
    
    accuracy = analytics.get("accuracy_rate", 0.7)
    consistency = analytics.get("consistency_score", 0.7)
    improvement = analytics.get("improvement_rate", 0.1)
    
    adjusted_difficulty = base_difficulty
    
    # ×”×ª×××” ×œ×¤×™ ×“×™×•×§
    if accuracy < 0.6:
        adjusted_difficulty -= 1
    elif accuracy > 0.85:
        adjusted_difficulty += 1
    
    # ×”×ª×××” ×œ×¤×™ ×¢×§×‘×™×•×ª
    if consistency < 0.5:
        adjusted_difficulty -= 1
    
    # ×”×ª×××” ×œ×¤×™ ×§×¦×‘ ×©×™×¤×•×¨
    if improvement < 0:
        adjusted_difficulty -= 1
    elif improvement > 0.3:
        adjusted_difficulty += 1
    
    # ×•×™×“×•× ×©×”×§×•×©×™ ×‘×˜×•×•×— ×ª×§×™×Ÿ
    return max(1, min(5, adjusted_difficulty))


def generate_improvement_suggestions(analytics: Dict[str, Any], skill_category: str) -> List[str]:
    """
    ×™×¦×™×¨×ª ×”×¦×¢×•×ª ×©×™×¤×•×¨ ××•×ª×××•×ª ××™×©×™×ª
    """
    
    suggestions = []
    accuracy = analytics.get("accuracy_rate", 0.7)
    weak_areas = analytics.get("weak_areas", [])
    common_errors = analytics.get("common_errors", [])
    
    # ×”×¦×¢×•×ª ×œ×¤×™ ×“×™×•×§
    if accuracy < 0.6:
        suggestions.append("××•××œ×¥ ×œ×—×–×•×¨ ×¢×œ ×”×—×•××¨ ×”×‘×¡×™×¡×™ ×œ×¤× ×™ ××¢×‘×¨ ×œ×ª×¨×’×™×œ×™× ××ª×§×“××™×")
        suggestions.append("×ª×¨×’×œ ×ª×¨×’×™×œ×™× ×§×œ×™× ×™×•×ª×¨ ×œ×—×™×–×•×§ ×”×‘×™×˜×—×•×Ÿ")
    elif accuracy > 0.85:
        suggestions.append("××ª×” ××¦×˜×™×™×Ÿ! ×‘×•× × × ×¡×” ×ª×¨×’×™×œ×™× ×××ª×’×¨×™× ×™×•×ª×¨")
        suggestions.append("××•×›×Ÿ ×œ×¢×‘×•×¨ ×œ×¨××” ×”×‘××”")
    
    # ×”×¦×¢×•×ª ×œ×¤×™ ×ª×—×•××™ ×—×•×œ×©×”
    for area in weak_areas:
        if area == "complex_grammar":
            suggestions.append("×ª×¨×’×œ ×¢×•×“ ×“×§×“×•×§ - ×–×× ×™× ×•×ª×•×•×™ ×§×‘×™×¢×”")
        elif area == "vocabulary":
            suggestions.append("×”×¨×—×‘ ××ª ××•×¦×¨ ×”××™×œ×™× ×‘× ×•×©××™× ×™×•××™×•××™×™×")
        elif area == "pronunciation":
            suggestions.append("×ª×¨×’×œ ×”×’×™×™×” ×¢× ×”×§×¨××•×ª ××™×˜×™×•×ª")
    
    # ×”×¦×¢×•×ª ×œ×¤×™ ×˜×¢×•×™×•×ª × ×¤×•×¦×•×ª
    for error in common_errors:
        if error["type"] == "grammar" and error["count"] > 5:
            suggestions.append("×©×™× ×“×’×© ××™×•×—×“ ×¢×œ ×ª×¨×’×™×œ×™ ×“×§×“×•×§")
        elif error["type"] == "spelling" and error["count"] > 3:
            suggestions.append("×ª×¨×’×œ ×›×ª×™×‘×” ××™×˜×™×ª ×™×•×ª×¨ ×•×‘×“×•×§ ××™×•×ª")
    
    return suggestions[:3]  # ××’×‘×™×œ ×œ-3 ×”×¦×¢×•×ª